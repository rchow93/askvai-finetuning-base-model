{"instruction": "What is CrewAI and what is its purpose?", "input": "", "output": "CrewAI is a cutting-edge framework for orchestrating autonomous AI agents. It enables you to create teams of AI agents where each agent has specific roles, tools, and goals, working together to accomplish complex tasks. It's like assembling a dream team where each member brings unique skills and expertise, collaborating seamlessly."}
{"instruction": "How does the CrewAI framework work at a high level?", "input": "", "output": "CrewAI works by organizing AI agents into a collaborative structure, similar to a company with different departments.  Key components include:\n\n1.  **Agents:** Specialized team members with roles, goals, and tools.\n2.  **Tasks:** Individual assignments that agents complete.\n3.  **Process:**  The workflow management system that defines how agents collaborate (sequentially or hierarchically).\n4.  **Crew:** The top-level organization that manages the agents, tasks, and process.\n\nAgents work together, delegating tasks and sharing information, to achieve a common objective, defined by the Crew."}
{"instruction": "What are the key features of CrewAI?", "input": "", "output": "Key features of CrewAI include:\n\n*   **Role-Based Agents:**  Agents are assigned specific roles (e.g., Researcher, Writer) with corresponding goals and backstories.\n*   **Flexible Tools:** Agents can be equipped with custom tools and APIs to interact with external systems.\n*   **Intelligent Collaboration:** Agents can communicate, delegate tasks, and share insights.\n*   **Task Management:**  Supports sequential and hierarchical task execution.\n*   **Customizable:**  Allows for extensive configuration of agents, tools, and processes.\n*   **Memory and Context:** Agents can maintain memory of interactions and use context from previous tasks.\n*   **Code Execution:** Agents can be enabled to write and execute code.\n*   **Multimodal Capabilities:** Agents can process images and other non-text content.\n*   **Observability:** Integration with tools like AgentOps for monitoring and debugging.\n* **Planning:** Add planning ability to the Crew.\n*   **Delegation:** Agents can delegate tasks to other agents"}
{"instruction": "How do I install CrewAI?", "input": "", "output": "You can install CrewAI and its CLI using `uv`: First, make sure you have Python >=3.10 and <3.13. Then, install `uv` (if you don't have it) using `curl -LsSf https://astral.sh/uv/install.sh | sh` (macOS/Linux) or `powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"` (Windows). Finally, install the CrewAI CLI with: `uv tool install crewai`."}
{"instruction": "How do I create a new CrewAI project?", "input": "", "output": "You can create a new CrewAI project with a basic structure using the CLI command: `crewai create crew <your_project_name>`. This will create a directory with subfolders for agents, tasks, tools, config and a `main.py` file."}
{"instruction": "Explain the structure of a typical CrewAI project created with the CLI.", "input": "", "output": "A typical CrewAI project created with `crewai create crew <project_name>` has the following structure:\n\n```\n<project_name>/\n├── .gitignore\n├── knowledge/  (Optional, for custom knowledge sources)\n├── pyproject.toml\n├── README.md\n├── .env\n└── src/\n    └── <project_name>/\n        ├── __init__.py\n        ├── main.py\n        ├── crew.py\n        ├── tools/\n        │   ├── custom_tool.py\n        │   └── __init__.py\n        └── config/\n           ├── agents.yaml\n           └── tasks.yaml\n```\n\n*   `.gitignore`:  Specifies intentionally untracked files that Git should ignore.\n*   `knowledge/`: (Optional) Contains files used for custom knowledge sources.\n*   `pyproject.toml`:  Configuration file for project dependencies and settings (using `uv`).\n*   `README.md`:  A description of your project.\n*   `.env`:  Used to store API keys and other environment variables.\n*   `src/<project_name>/`:  Contains the main project code.\n    *   `__init__.py`:  Makes the directory a Python package.\n    *   `main.py`:  The entry point for running the crew.\n    *   `crew.py`:  Defines the Crew, Agents, and Tasks.\n    * `config/`: Contains YAML files for configuring agents (`agents.yaml`) and tasks (`tasks.yaml`).\n    *   `tools/`:  (Optional) Contains custom tool definitions.\n        *   `custom_tool.py`:  Example of a custom tool.\n        *   `__init__.py`:  Makes the `tools` directory a Python package."}
{"instruction": "How do I define an agent in CrewAI using Python code?", "input": "", "output": "You can define an agent using the `Agent` class, providing attributes like `role`, `goal`, `backstory`, and optionally `tools`, `llm`, `verbose`, `allow_delegation`, and others.  For example:\n\n```python\nfrom crewai import Agent\n\nresearcher = Agent(\n    role='Senior Research Analyst',\n    goal='Uncover cutting-edge developments in AI',\n    backstory='An expert researcher in AI and data science.',\n    verbose=True,\n    allow_delegation=False\n)\n```"}
{"instruction": "How do I define an agent in CrewAI using YAML?", "input": "", "output": "You can define agents in a YAML file (typically `agents.yaml`), specifying attributes like `role`, `goal`, `backstory`, and optionally `tools`, `llm`, `verbose`, and `allow_delegation`. For example:\n\n```yaml\nresearcher:\n  role: \"{topic} Senior Data Researcher\"\n  goal: \"Uncover cutting-edge developments in {topic}\"\n  backstory: \"You're a seasoned researcher ...\"\n```\n You can then reference that file when creating your crew."}
{"instruction": "How do I define a task in CrewAI using Python code?", "input": "", "output": "You define a task using the `Task` class, specifying a `description`, `expected_output`, and the `agent` assigned to it.  You can also include `tools`, `context`, and other attributes. Example:\n\n```python\nfrom crewai import Task\n\ntask = Task(\n    description='Research the latest advancements in AI.',\n    expected_output='A summary of recent AI breakthroughs.',\n    agent=researcher_agent\n)\n```"}
{"instruction": "How can I define tasks in CrewAI using YAML?", "input": "", "output": 'You can define tasks in a YAML file, such as `tasks.yaml`.  Each task should have a `description`, `expected_output`, and the `agent` it\'s assigned to.  Example:\n\n```yaml\nresearch_task:\n  description: "Conduct a thorough research about {topic}"\n  expected_output: "A list with 10 bullet points of the most relevant information about {topic}"\n  agent: researcher\n```'}
{"instruction": "How do I create a Crew in CrewAI?", "input": "", "output": "You create a crew using the `Crew` class, passing in the `agents` and `tasks`. You can also specify the `process` (e.g., `Process.sequential` or `Process.hierarchical`). Example using code:\n\n```python\nfrom crewai import Crew, Process\n\ncrew = Crew(\n    agents=[researcher_agent, writer_agent],\n    tasks=[research_task, writing_task],\n    process=Process.sequential\n)\n```\n\nExample using YAML:\n```python\nfrom crewai.project import CrewBase, agent, task, crew\n\n@CrewBase\nclass MyCrew():\n agents_config = \"config/agents.yaml\"\n tasks_config = \"config/tasks.yaml\"\n\n @agent\n def researcher(self) -> Agent:\n  ... # Load agent from config\n\n```"}
{"instruction": "How do I run a Crew in CrewAI?", "input": "", "output": "After creating your crew, you run it using the `kickoff()` method. This starts the task execution process.  Example: `result = crew.kickoff()`"}
{"instruction": "What are the different process types available in CrewAI?", "input": "", "output": "CrewAI supports two main process types:\n\n*   **`Process.sequential`:** Tasks are executed one after the other, in the order they are defined in the `tasks` list.\n*   **`Process.hierarchical`:**  A manager agent coordinates the crew, delegating tasks and validating outcomes.  Requires either `manager_llm` or `manager_agent` to be specified."}
{"instruction": "Explain the sequential process in CrewAI.", "input": "", "output": "The sequential process executes tasks in the order they are defined in the `tasks` list provided to the `Crew` object.  Each task is completed before the next one begins. The output of one task can be used as context for subsequent tasks."}
{"instruction": "How does the hierarchical process work in CrewAI?", "input": "", "output": "The hierarchical process in CrewAI implements a manager-workers structure that enables sophisticated collaboration patterns:\n\n1. Basic setup:\n```python\nfrom crewai import Crew, Process\n\ncrew = Crew(\n    agents=[manager_agent, worker1, worker2, worker3],\n    tasks=[main_task],\n    process=Process.hierarchical\n)\n```\n\n2. Execution flow:\n   - A manager agent is automatically selected or explicitly defined\n   - The manager receives the main task and creates a plan\n   - The manager delegates subtasks to appropriate worker agents\n   - Workers execute their assigned subtasks and report results\n   - The manager coordinates, provides feedback, and consolidates results\n\n3. Custom manager definition:\n```python\n# Define a specific agent as the manager\ncrew = Crew(\n    agents=[worker1, worker2, worker3],\n    tasks=[main_task],\n    manager_agent=custom_manager,  # Explicitly set the manager\n    process=Process.hierarchical\n)\n```\n\n4. Manager's language model:\n```python\n# Specify a powerful LLM for the manager's coordination duties\ncrew = Crew(\n    agents=[worker1, worker2, worker3],\n    tasks=[main_task],\n    process=Process.hierarchical,\n    manager_llm=\"gpt-4o\"  # Use a specific model for the manager\n)\n```\n\nThe hierarchical process is best suited for complex projects requiring intelligent task decomposition, coordination, and oversight."}
{"instruction": "How can I use tools with CrewAI agents?", "input": "", "output": "Agents can be equipped with tools to enhance their capabilities. You can specify tools when defining an agent using the `tools` parameter, which accepts a list of `BaseTool` instances.  CrewAI provides built-in tools (in `crewai_tools`), and you can create custom tools by subclassing `BaseTool` or using the `@tool` decorator."}
{"instruction": "How do I create a custom tool in CrewAI by subclassing BaseTool?", "input": "", "output": "To create a custom tool by subclassing `BaseTool`, you need to define a class that inherits from `BaseTool` and implement the `_run` method.  You should also define the `name` and `description` attributes, and optionally the `args_schema` for input validation.  Example:\n\n```python\nfrom crewai.tools import BaseTool\nfrom pydantic import BaseModel, Field\nfrom typing import Type\n\nclass MyToolInput(BaseModel):\n    argument: str = Field(..., description=\"Description of the argument.\")\n\nclass MyCustomTool(BaseTool):\n    name: str = \"Name of my tool\"\n    description: str = \"What this tool does.\"\n    args_schema: Type[BaseModel] = MyToolInput\n\n    def _run(self, argument: str) -> str:\n        # Your tool's logic here\n        return \"Tool's result\"\n```"}
{"instruction": "How can I create a custom tool using the @tool decorator in CrewAI?", "input": "", "output": "You can create a custom tool using the `@tool` decorator by defining a function and decorating it with `@tool`, providing the tool's name as an argument.  The function's docstring will be used as the tool's description. Example:\n\n```python\nfrom crewai.tools import tool\n\n@tool(\"Name of my tool\")\ndef my_tool(question: str) -> str:\n    \"\"\"Clear description for what this tool is useful for.\"\"\"\n    # Function logic here\n    return \"Result from your custom tool\"\n```"}
{"instruction": "How can I enable an agent to execute code?", "input": "", "output": "To enable code execution for an agent, set the `allow_code_execution` parameter to `True` when creating the agent.  It's recommended to use more capable models (like Claude 3.5 Sonnet or GPT-4) when enabling code execution. It defaults to `False`."}
{"instruction": "What is the purpose of the `context` attribute in a CrewAI Task?", "input": "", "output": "The `context` attribute allows you to specify a list of other tasks whose outputs should be used as context for the current task. This is useful for creating dependencies between tasks, where the output of one task is needed as input for another."}
{"instruction": "How can I make a task execute asynchronously in CrewAI?", "input": "", "output": "You can make a task execute asynchronously by setting the `async_execution` attribute to `True` when defining the task. This allows the crew to continue with other tasks without waiting for the asynchronous task to complete."}
{"instruction": "How do I access the output of a task in CrewAI?", "input": "", "output": "Once a crew has finished executing, you can access the output of a specific task using the `output` attribute of the `Task` object.  This attribute will be an instance of `TaskOutput`, which provides access to the raw output, and potentially structured output (JSON or Pydantic) if configured."}
{"instruction": "How can I get structured output from a CrewAI task?", "input": "", "output": "You can get structured output from a task by using either the `output_pydantic` or `output_json` attributes when defining the task.  `output_pydantic` expects a Pydantic model class, while `output_json` can work directly with JSON, guided by the structure provided."}
{"instruction": "What are Task Guardrails in CrewAI?", "input": "", "output": "Task Guardrails are validation functions that you can define to check and potentially transform the output of a task *before* it's passed to the next task.  They help ensure data quality and provide feedback to agents if their output doesn't meet requirements."}
{"instruction": "How do I define a Task Guardrail in CrewAI?", "input": "", "output": "You define a guardrail by creating a function that takes the task output (a string) as input and returns a tuple: `(bool, Any)`.  The boolean indicates success (True) or failure (False).  If `True`, the second element is the validated/transformed result. If `False`, the second element is an error message/object.  You then assign this function to the `guardrail` attribute of the `Task`."}
{"instruction": "What happens if a Task Guardrail fails in CrewAI?", "input": "", "output": "If a guardrail function returns `(False, error)`, the error is sent back to the agent, and the agent will attempt to fix the issue and re-execute the task. This process repeats until the guardrail passes or the maximum number of retries (`max_retries`) is reached."}
{"instruction": "How do I use the `crewai kickoff_for_each` method?", "input": "List of dictionaries, each representing input for one crew execution.", "output": "The `crew.kickoff_for_each()` method allows you to run a crew multiple times, once for each item in a list of inputs. This is useful for processing multiple datasets or scenarios with the same crew configuration. You pass a list of dictionaries to the `inputs` argument. Each dictionary represents the input for one crew execution."}
{"instruction": "How can I run a CrewAI crew asynchronously?", "input": "", "output": "You can run a crew asynchronously using the `kickoff_async()` method.  This starts the crew execution in a separate thread (or event loop, using `asyncio`). You'll need to use `await` to get the result.  Example:\n\n```python\nimport asyncio\n\nasync def main():\n    crew = Crew(...)\n    result = await crew.kickoff_async(inputs=...)\n    print(result)\n\nasyncio.run(main())\n```"}
{"instruction": "How do I connect CrewAI to different Large Language Models (LLMs)?", "input": "", "output": "CrewAI uses LiteLLM to connect to various LLMs. You can specify the LLM when creating an agent using the `llm` parameter. You can pass either a string identifier (e.g., `'gpt-4'`, `'claude-2'`) or an instance of the `LLM` class for more fine-grained control. You may need to set environment variables like `OPENAI_API_KEY`, `OPENAI_API_BASE`, etc., depending on the provider."}
{"instruction": "What is the purpose of the `memory` attribute in a CrewAI Agent?", "input": "", "output": "The `memory` attribute, when set to `True`, enables the agent to maintain context across multiple interactions, improving its ability to handle complex, multi-step tasks. It uses short-term, long-term and entity memories to achieve the goal."}
{"instruction": "What is the purpose of the `verbose` attribute in CrewAI?", "input": "", "output": "The `verbose` attribute controls the level of logging output. When set to `True`, it enables detailed logging of agent actions and execution steps, which is useful for debugging and understanding the agent's behavior. It also accepts an integer to set a specific verbosity level"}
{"instruction": "How do I set a custom manager agent for a hierarchical crew in CrewAI?", "input": "", "output": "You can set a custom manager agent using the `manager_agent` attribute when creating the `Crew` object.  This allows you to specify a specific `Agent` instance to act as the manager, giving you full control over its behavior and capabilities. For example `crew = Crew(agents=[researcher, writer], tasks=[task], manager_agent=custom_manager, process=Process.hierarchical)`"}
{"instruction": "What is the purpose of the `max_rpm` attribute in CrewAI?", "input": "", "output": "The `max_rpm` attribute allows you to set the maximum requests per minute the agent (or crew) is allowed to make.  This is useful for avoiding rate limits when interacting with external APIs or services."}
{"instruction": "How can I use YAML files to configure agents and tasks in CrewAI?", "input": "", "output": "CrewAI supports using YAML files to define agents and tasks. You typically create `agents.yaml` and `tasks.yaml` files. You can then use a `CrewBase` class with the `@agent`, `@task`, and `@crew` decorators to load the configurations from these files."}
{"instruction": "Explain the role of the `before_kickoff` and `after_kickoff` decorators in CrewAI.", "input": "", "output": "The `@before_kickoff` and `@after_kickoff` decorators allow you to define methods that will be executed before and after the crew's execution, respectively.  These are useful for pre-processing inputs (`before_kickoff`) or post-processing outputs (`after_kickoff`)."}
{"instruction": "What is CrewAI AgentOps, and how does it relate to CrewAI?", "input": "", "output": "AgentOps is a *separate* product that provides observability for conversational AI agents, including those built with CrewAI. It allows you to monitor cost, token usage, latency, agent failures, session replays, and more.  It's not part of the CrewAI library itself, but integrates with it."}
{"instruction": "How do I integrate AgentOps with CrewAI?", "input": "", "output": "To integrate AgentOps, you need to:\n\n1.  Create an AgentOps API key.\n2.  Install the `crewai[agentops]` package (or `agentops`).\n3.  Add `import agentops` and `agentops.init()` at the beginning of your CrewAI script.\n4. Set the `AGENTOPS_API_KEY` environment variable.\n\nThis will automatically track your CrewAI agents' performance."}
{"instruction": "What is the `planning` attribute in the `Crew` class and what does it do?", "input": "", "output": "The `planning` attribute, when set to `True` when instantiating the `Crew` class, adds planning capabilities to the crew using an `AgentPlanner`. When enabled, the crew will use an `AgentPlanner` to plan tasks step-by-step *before* each crew iteration, and this plan is added to each task description."}
{"instruction": "Explain the concept of \"delegation\" in CrewAI.", "input": "", "output": "Delegation in CrewAI refers to an agent's ability to assign tasks or subtasks to other agents within the crew.  The `allow_delegation` attribute on an `Agent` controls whether that agent is permitted to delegate. By default is set to `False`."}
{"instruction": "What is the purpose of the `function_calling_llm` attribute in CrewAI?", "input": "", "output": "The `function_calling_llm` attribute allows you to specify a separate language model specifically for handling tool/function calls. This can be useful for optimizing performance or cost, as you might use a smaller, faster model for function calling and a more powerful model for general reasoning. It can also be specified on a crew level."}
{"instruction": "What is the purpose of the `output_file` attribute in a CrewAI Task?", "input": "", "output": "The `output_file` attribute, when specified in a `Task`, allows you to automatically save the task's output to a file at the given path. You can now also use the `create_directory=True` to create the necessary folder for the output file"}
{"instruction":"How can I force the output of a tool execution to be used as an answer", "input": "", "output": "You can force the output of a specific tool usage to be captured and returned as the task output by setting the `result_as_answer` parameter to `True` when passing the tool to the agent's `tools` list."}
{"instruction":"How can force a task to wait on the completion of an async task before it starts", "input": "", "output": "Use the `context` attribute, you can set a list of tasks that your current tasks will have to wait on before starting."}
{"instruction":"What is the difference between the `crewai run` and `crewai flow kickoff` commands?", "input": "", "output":"`crewai run` command detects whether your CrewAI setup is a crew or flow based on `pyproject.toml`, and then executes `crewai crew run` or `crewai flow kickoff`. `crewai flow kickoff` specifically runs a CrewAI flow."}
{"instruction":"How can I replay a specific task from the latest crew kickoff using the CrewAI CLI?", "input": "", "output":"First, use `crewai log-tasks-outputs` to view the latest kickoff task IDs. Then, use `crewai replay -t <task_id>` to replay the task with the specified ID. Make sure you replace `<task_id>` with the actual ID."}
{"instruction":"How do I reset the memory of a CrewAI crew or agent?", "input": "", "output": "You can reset different types of memory (long-term, short-term, entity, latest kickoff outputs) using the `crewai reset-memories` command in the CLI.  For example, `crewai reset-memories --long --short` resets long-term and short-term memory.  `crewai reset-memories --all` resets all memory types."}
{"instruction":"What is the purpose of the `step_callback` attribute on an agent?", "input":"", "output":"The `step_callback` allows you to specify a function that will be called after *each step* of the agent's execution. This provides a way to monitor the agent's progress, log intermediate results, or perform other actions at each step. The step callback for the agent will override the crew's `step_callback`."}
{"instruction":"What is the purpose of the `task_callback` attribute on a crew?", "input":"", "output":"The `task_callback` allows you to specify a function that will be called after *each task completion*. This provides a way to monitor the progress, log results, or perform other actions."}
{"instruction":"How can I share the complete crew information and execution with the crewAI team?", "input":"", "output":"You can share the complete crew information and execution data with the CrewAI team, to help them to make the library better, and allow them to train models by setting the `share_crew` attribute to `True` when instantiating a crew."}
{"instruction":"How can I add planning ability to my crew?", "input":"", "output":"You can add planning ability to the Crew. When activated before each Crew iteration, all Crew data is sent to an AgentPlanner that will plan the tasks and this plan will be added to each task description by setting the `planning` attribute to `True` when instantiating a crew."}
{"instruction":"How can I add planning ability to my crew and specify the LLM for the `AgentPlanner`?", "input":"", "output":"You can add planning ability to the Crew. When activated before each Crew iteration, all Crew data is sent to an AgentPlanner that will plan the tasks and this plan will be added to each task description by setting the `planning` attribute to `True` and the `planning_llm` to your desired LLM, when instantiating a crew."}
{"instruction":"What's the purpose of and_() and or_() in crewai.flow?", "input": "", "output": "The `and_()` and `or_()` functions, used with the `@listen` decorator in CrewAI Flows, provide conditional logic for task execution. `and_()` triggers a listener method only when *all* specified methods have emitted an output, while `or_()` triggers it when *any* of the specified methods emit an output."}
{"instruction":"What's the purpose of the `@router` decorator in crewai.flow?", "input": "", "output":"The `@router(method)` decorator in CrewAI Flows allows you to define conditional routing logic based on the output of the `method`.  You can then use `@listen(\"output_value\")` on other methods to specify which methods should be executed based on the return value of the routed method."}
{"instruction":"How can I add a user-specific memory component to my CrewAI crew?", "input": "", "output": "You can use the `Mem0` library to add user-specific memory.  You'll need a `MEM0_API_KEY`.  Then, when creating your `Crew`, set `memory=True` and provide a `memory_config` dictionary like this:\n\n```python\nmemory_config={\n    \"provider\": \"mem0\",\n    \"config\": {\"user_id\": \"your_user_id\"}\n}\n```\n\nYou can also specify `org_id` and `project_id` in the config."}
{"instruction":"What different embedding providers are supported by the CrewAI `memory` feature, and how do I configure them?", "input":"", "output":"CrewAI, through its integration with libraries like `chromadb`, supports various embedding providers. Some of the supported providers include OpenAI, Cohere, Hugging Face, Ollama, and others.  You configure the provider using the `embedder` parameter when creating a `Crew` or `Agent`.  For example:\n\n```python\ncrew = Crew(\n    # ... other parameters ...\n    embedder={\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": \"text-embedding-3-small\"\n        }\n    }\n)\n```\n\nDifferent providers will require different configuration parameters (e.g., API keys, model names, base URLs). Refer to the CrewAI documentation and the documentation for the specific embedding provider (like LiteLLM) for details."}
{"instruction":"What are the different types of memory supported in CrewAI?", "input": "", "output": "CrewAI supports several types of memory to enhance agent capabilities:\n\n- **Short-Term Memory:** Stores recent interactions and outcomes using RAG, useful for maintaining context within the current execution.\n- **Long-Term Memory:** Preserves valuable insights and learnings from *past* executions, allowing agents to build and refine their knowledge over time.  Uses SQLite3 by default.\n- **Entity Memory:** Captures and organizes information about specific entities (people, places, concepts) encountered during tasks.\n- **Contextual Memory:**  Combines Short-Term, Long-Term, and Entity Memory to maintain overall coherence and relevance.\n- **User Memory (using Mem0):** Stores user-specific information and preferences."}
{"instruction":"How can I make sure files are created when using the output_file attribute on my tasks?", "input":"", "output":"You can use the `create_directory=True` attribute on the task."}

{"instruction": "How can I limit the number of times an agent retries a task if an error occurs?", "input": "", "output": "You can limit the number of retries using the `max_retry_limit` attribute when defining a `Task`. For example: `task = Task(..., max_retry_limit=3)` will limit retries to 3 attempts."}
{"instruction": "What happens if an agent's `max_iter` limit is reached?", "input": "", "output": "If an agent reaches its `max_iter` limit (default is 20), it will stop iterating and provide its best answer at that point, even if it hasn't fully converged on a solution."}
{"instruction": "How do I ensure that a task's output is saved to a file?", "input": "", "output": "Use the `output_file` attribute when defining the `Task`.  For example: `task = Task(..., output_file='results/output.txt')`.  This will save the raw output to the specified file."}
{"instruction": "Can I use a custom logging format with CrewAI agents?", "input": "", "output": "While CrewAI's built-in `verbose` mode provides basic logging, you can achieve more customized logging by using the `step_callback` attribute on an `Agent` or the `task_callback` and `step_callback` attributes of `Crew` to define a custom function that handles logging. This function will receive information about each step or task."}
{"instruction": "How can I prevent an agent from delegating tasks?", "input": "", "output": "Set the `allow_delegation` attribute to `False` when defining the agent. By default, it is now set to `False`."}
{"instruction": "What happens if a task's `guardrail` function raises an exception?", "input": "", "output": "If a guardrail function raises an exception, it will be treated as a validation failure. The agent will receive an error message and may attempt to retry the task (up to `max_retries`).  It's good practice to handle potential exceptions *within* your guardrail function and return a `(False, error_message)` tuple."}
{"instruction": "If I have multiple agents in a crew, how does CrewAI decide which agent executes a task?", "input": "", "output": "In a sequential process (`Process.sequential`), the agent explicitly assigned to the task (`task.agent`) will execute it. In a hierarchical process (`Process.hierarchical`), the manager agent will delegate the task to an appropriate agent based on its role and capabilities, or the `manager_llm` will be used."}
{"instruction": "How can I provide additional context to a task beyond the output of other tasks?", "input": "", "output": "You can use the `description` parameter to include additional context when the crew is executed, or use variables in the description that you provide when the crew is being kicked off."}
{"instruction": "Can I modify the behavior of a CrewAI agent after it has been created?", "input": "", "output": "While you can't directly modify the core attributes (like `role`, `goal`, `backstory`) of an agent after creation, you *can* dynamically change the `tools` available to an agent, and you can influence its behavior through task descriptions, context, and guardrails."}
{"instruction": "How does the `respect_context_window` attribute affect agent behavior?", "input": "", "output": "When `respect_context_window` is set to `True` (which is the default), the agent will attempt to keep the conversation history within the context window limits of the underlying language model. It may summarize or truncate previous messages to achieve this. If set to false, context might overflow."}
{"instruction": "What is the purpose of the `use_system_prompt` attribute for an Agent?", "input": "", "output": "The `use_system_prompt` attribute (defaulting to `True`) controls whether the agent uses a system prompt during task execution. This is primarily relevant for older models that may not fully support system messages. Set to `False` for o1 model support."}
{"instruction": "What happens if I don't specify an `agent` for a task in a sequential process?", "input": "", "output": "If you don't specify an `agent` for a task in a sequential process, you will get an error. Each task *must* have an assigned agent in a sequential process."}
{"instruction":"How can I set a default LLM for all agents in a crew?", "input":"", "output":"You can set a default LLM using environment variables.  Set `OPENAI_MODEL_NAME` to your desired model (e.g., `OPENAI_MODEL_NAME=gpt-4o-mini`). This will be used as the default if an agent doesn't have a specific `llm` configured."}
{"instruction": "How does the caching mechanism work in CrewAI tools?", "input": "", "output": "By default, CrewAI tools have caching enabled (`cache=True`). This means that if a tool is called with the same arguments multiple times, the cached result will be returned instead of re-executing the tool. This can improve performance and reduce API calls. You can disable caching by setting `cache=False` on an agent or tool, or define custom caching logic using the `cache_function` parameter."}
{"instruction": "How do I define a custom caching strategy for a CrewAI tool?", "input": "", "output": "You can define a custom caching strategy by providing a `cache_function` to the tool. This function should accept the tool's arguments and the result as input, and return `True` if the result should be cached, and `False` otherwise. For example:\n\n```python\n@tool\ndef my_tool(...):\n    ...\n\ndef my_cache_function(args, result):\n  return result % 2 == 0  # Cache only even results\n\nmy_tool.cache_function = my_cache_function\n```"}
{"instruction": "What happens if an error occurs during the execution of a custom tool's `_run` method?", "input": "", "output": "If an error occurs within the `_run` method of a custom tool, the agent will receive an error message and may attempt to retry the task (if `max_retries` is greater than 0).  It's important to implement proper error handling within your `_run` method."}
{"instruction": "How can I use environment variables to configure CrewAI?", "input": "", "output": "CrewAI uses environment variables for several configurations, such as API keys and default model names.  For example, you can set `OPENAI_API_KEY`, `OPENAI_API_BASE`, `OPENAI_MODEL_NAME`, `SERPER_API_KEY`, and `CREWAI_STORAGE_DIR`.  It's recommended to use a `.env` file to manage these variables."}
{"instruction":"What's the best way to structure a larger CrewAI project?", "input": "", "output": "For larger projects, it's recommended to use the project structure generated by `crewai create crew`. This includes separate files for agents (`agents.yaml`), tasks (`tasks.yaml`), custom tools (in a `tools` directory), and the main crew logic (`crew.py`). Using YAML files for configuration can improve readability and maintainability."}
{"instruction": "Can I use CrewAI with LangChain tools?", "input": "", "output": "Yes, CrewAI is designed to be compatible with LangChain tools. You can include LangChain tools in the `tools` list of an agent."}
{"instruction":"How do I pass inputs to a crew when using `crew.kickoff()`?", "input":"", "output": "You can pass inputs to the crew using the `inputs` parameter of the `kickoff()` method. This should be a dictionary where keys correspond to variables used in your task descriptions or agent configurations (if using YAML). Example: `crew.kickoff(inputs={'topic': 'AI'})`"}
{"instruction":"What's the difference between `crew.kickoff()` and `crew.kickoff_async()`?", "input":"", "output":"`crew.kickoff()` runs the crew synchronously, blocking until the crew completes.  `crew.kickoff_async()` runs the crew asynchronously, returning a coroutine that you can `await` to get the result.  `kickoff_async` is useful for running multiple crews concurrently or performing other tasks while the crew is running."}
{"instruction":"How do I run multiple crews concurrently in CrewAI?", "input":"", "output":"You can run multiple crews concurrently using `asyncio.gather()` with the `kickoff_async()` method of each crew. Example:\n\n```python\nimport asyncio\n\nasync def main():\n    crew1 = Crew(...)\n    crew2 = Crew(...)\n    results = await asyncio.gather(crew1.kickoff_async(), crew2.kickoff_async())\n    print(results)\n\nasyncio.run(main())\n```"}
{"instruction":"What is the `CrewOutput` object returned by `crew.kickoff()`?", "input":"", "output":"The `CrewOutput` object contains the results of the crew's execution.  It has attributes like `raw` (the raw output), `pydantic` (if `output_pydantic` was used), `json_dict` (if `output_json` was used), `tasks_output` (a list of `TaskOutput` objects for each task), and `token_usage`."}
{"instruction":"How can I use the `output_log_file` setting in a Crew?", "input":"", "output":"The `output_log_file` setting in the `Crew` constructor allows you to save logs of the crew's execution. You can set it to `True` to save logs to `logs.txt`, or provide a file path (e.g., `'logs/my_log.json'`). If the filename ends with `.json`, the logs will be in JSON format; otherwise, they'll be in `.txt` format. If set to `None` no logs will be saved"}
{"instruction": "Can I use a combination of YAML and code definitions for agents and tasks?", "input": "", "output": "Yes, you can mix YAML and code definitions. For example, you could define your agents in `agents.yaml` and then create tasks programmatically in your Python code, referencing those agents."}
{"instruction":"How do I add a custom attribute to an Agent's state in a structured way?", "input": "", "output":"If you're using structured state management (by defining a Pydantic `BaseModel` for your `Flow`'s state), you add custom attributes by adding fields to that `BaseModel`. If using unstructured state, just add or change attributes."}
{"instruction":"If a tool requires an API key, where is the best place to store and access it?", "input": "", "output":"The recommended practice is to store API keys in environment variables (e.g., using a `.env` file) and access them using `os.environ`. This keeps sensitive information out of your codebase."}
{"instruction":"What happens if an agent tries to use a tool that hasn't been installed or configured correctly?", "input":"", "output":"If an agent tries to use a tool that isn't available (e.g., missing dependencies), CrewAI will typically raise an error or log a message indicating that the tool couldn't be used."}
{"instruction": "How can I see the intermediate steps and reasoning of an agent during task execution?", "input": "", "output": "Enable verbose mode by setting `verbose=True` when creating the `Agent` or `Crew`. This will print detailed logs to the console, showing the agent's thought process, tool usage, and intermediate results. You can also use the AgentOps integration to get in depth monitoring, or define a `step_callback`."}
{"instruction": "Can I use CrewAI to build a chatbot?", "input": "", "output": "Yes, CrewAI can be used to build chatbots. You would typically define agents with roles and goals relevant to the chatbot's functionality, and tasks that represent user interactions. You can also use a flow and set the `chat_llm` parameter to the model you want to use"}
{"instruction": "How do I specify the order of tasks in a hierarchical process?", "input": "", "output": "In a hierarchical process, the *manager agent* is responsible for determining the order and delegation of tasks. The initial `tasks` list provided to the `Crew` object is less important in this case; the manager dynamically creates and assigns subtasks."}
{"instruction":"How do I handle situations where a task might fail due to external factors (e.g., API outage)?", "input":"", "output": "You can use the `max_retries` attribute on a `Task` to automatically retry the task a certain number of times.  You can also implement custom error handling within your agent's logic or within custom tools."}
{"instruction":"How do I provide feedback to an agent during its execution?", "input": "", "output":"In a sequential process, it's more difficult to give direct feedback *during* execution. You mainly guide by defining a task with `human_input=True`. In a hierarchical process, the manager agent can provide feedback and redirect tasks based on intermediate results. You can also use `step_callback` or `task_callback` to get info."}
{"instruction":"How can I set a time limit for a task's execution?", "input":"", "output":"You can use the `max_execution_time` attribute when creating a `Task` to set a maximum execution time in seconds. The task will be interrupted if it exceeds this limit."}
{"instruction": "What happens if an agent's generated code produces a syntax error?", "input": "", "output":"If code execution is enabled and the agent generates code with a syntax error, the `CodeInterpreterTool` will catch the error, and the agent will receive an error message. It can then attempt to correct the code (up to `max_retries` times)."}
{"instruction": "Can I use different LLMs for different agents within the same crew?", "input": "", "output": "Yes, you can specify a different `llm` for each agent when creating them. This allows you to use specialized models for different roles or tasks."}
{"instruction": "How can I access the raw output of a tool used by an agent, even if `result_as_answer` isn't set?", "input": "", "output": "The raw output of tools is not *directly* accessible as a separate attribute. You need to use `verbose=True` and check the logs to see the output of the tool execution, you can also use the callback functions to log intermediate results."}
{"instruction":"How can I load agents and tasks from YAML files dynamically based on user input?", "input":"", "output":"You can load YAML files using a library like `PyYAML`, and then use the data to create `Agent` and `Task` instances dynamically based on user input or other runtime conditions."}
{"instruction":"Can I use CrewAI with asynchronous task execution with Langchain tools?", "input":"", "output": "Yes. You need to create the langchain tools with the async version of the tool"}
{"instruction": "What's the recommended way to handle very long text inputs or outputs that might exceed the context window of the LLM?", "input": "", "output": "CrewAI has `respect_context_window` set to `True` by default. This enables a sliding context window and automatically shortens messages that would overflow the context window of the LLM"}
{"instruction": "How to get a list of available LLM providers in CrewAI?", "input": "", "output": "You can see the top 5 LLM providers when initializing a crew. You can also see the full list of LLM providers that are supported through LiteLLM in the CrewAI documentation or through `crewai [COMMAND] [OPTIONS] [ARGUMENTS]`."}
{"instruction": "How to use the `crewai test` command?", "input": "", "output": "The `crewai test` command is used to test a crew and evaluate its results. It runs the crew for a specified number of iterations (default: 3) and uses a specified LLM model (default: \"gpt-4o-mini\"). You can specify the number of iterations with `--n_iterations` or `-n` and the model with `--model` or `-m`. For example: `crewai test -n 5 -m gpt-3.5-turbo`"}
{"instruction": "What is the `crewai run` command and when should it be used?", "input": "", "output": "The `crewai run` command (introduced in version 0.103.0) is the recommended way to run both standard crews and flows. It automatically detects the type (crew or flow) from `pyproject.toml` and executes the appropriate command. Use this instead of `crewai crew run` or `crewai flow kickoff` for new projects."}
{"instruction": "What is the `crewai chat` command and how does it work?", "input": "", "output": "The `crewai chat` command (introduced in version 0.98.0) starts an interactive session with your crew. The AI assistant guides you by asking for necessary inputs to execute the crew.  Once all inputs are provided, the crew executes its tasks, and you can continue interacting with the assistant.  You need to set the `chat_llm` property in your `crew.py` file to enable this command."}
{"instruction": "How do I set up API keys for LLM providers when using the CrewAI CLI?", "input": "", "output": "When you run `crewai create crew`, the CLI will prompt you to select an LLM provider and then ask for the necessary API keys.  It supports providers like OpenAI, Groq, Anthropic, Google Gemini, and SambaNova out of the box.  For other providers supported by LiteLLM, you'll be prompted for the key name and the API key."}
{"instruction": "What commands are available in the CrewAI CLI?", "input": "", "output": "The CrewAI CLI provides several commands, including:\n\n-   `create`: Creates a new crew or flow.\n-   `version`: Shows the installed version of CrewAI and optionally tools.\n-   `train`: Trains the crew for a specified number of iterations.\n-   `replay`: Replays the crew execution from a specific task.\n-   `log-tasks-outputs`: Retrieves the latest `crew.kickoff()` task outputs.\n-   `reset-memories`: Resets the crew memories (long, short, entity, latest kickoff outputs).\n-   `test`: Tests the crew and evaluates the results.\n-   `run`: Runs the crew or flow (recommended for both).\n-   `chat`: Starts an interactive session with the crew."}
{"instruction": "How to use the `crewai train` command?", "input": "", "output": "The `crewai train` command is used to train your AI agents using the command-line interface (CLI). You can specify the number of iterations for the training process using the `-n` option. For example: `crewai train -n 10`"}
{"instruction": "How to use the `crewai log-tasks-outputs` command?", "input": "", "output": "The `crewai log-tasks-outputs` command retrieves the latest `crew.kickoff()` task outputs."}
{"instruction": "How to use the `crewai version` command?", "input": "", "output": "The `crewai version` command shows the installed version of CrewAI. You can use the `--tools` option to show the installed version of CrewAI tools. For example: `crewai version --tools`"}
{"instruction": "Explain the parameters that can be used to customize the testing behavior with the `crewai test` CLI command.", "input": "", "output": "`crewai test` takes the following parameters:\n    * `-n, --n_iterations INTEGER`:  Number of iterations to test the crew (default: 3).\n    * `-m, --model TEXT`:  LLM Model to run the tests on the Crew (default: \"gpt-4o-mini\")."}
{"instruction": "Explain the different options available for the `crewai reset-memories` command.", "input": "", "output": "The `crewai reset-memories` command takes the following options:\n    * `-l, --long`: Reset LONG TERM memory.\n    * `-s, --short`: Reset SHORT TERM memory.\n    * `-e, --entities`: Reset ENTITIES memory.\n    * `-k, --kickoff-outputs`: Reset LATEST KICKOFF TASK OUTPUTS.\n    * `-a, --all`: Reset ALL memories.\n    * `-kn, --knowledge` Reset KNOWLEDGE memory."}

{"instruction": "What is the function of `crewai.tools.structured_tool.CrewStructuredTool`?", "input": "", "output": "The `CrewStructuredTool` class wraps functions as tools, providing flexibility and validation while reducing boilerplate. It supports custom schemas and dynamic logic for the seamless integration of complex functionalities, allowing you to interact with external APIs."}
{"instruction":"How to check if a tool has a cache function?", "input": "", "output": "check the tool for the cache_function attribute, all tools in the `crewai-tools` package support caching. For custom tools, the cache_function needs to be defined"}
{"instruction": "How can I customize the prompt template for an agent?", "input": "", "output": "You can customize the prompt template for an agent using the `prompt_template` attribute. This allows you to define a custom prompt template for the agent."}
{"instruction": "How can I customize the response template for an agent?", "input": "", "output": "You can customize the response template for an agent using the `response_template` attribute. This allows you to define a custom response template for the agent."}
{"instruction": "Can i use all the langchain tools with crewai?", "input": "", "output": "Yes, all langchain tools are supported"}
{"instruction":"I want to pass an int and a string to my `BaseTool`. How can I do that?", "input":"", "output":"Create a pydantic class that inherits from `BaseModel`, then define the types of the parameters that you want to input to the tool.\n```python\nfrom pydantic import BaseModel, Field\n\nclass MyToolInput(BaseModel):\n    number: int = Field(description=\"input an int\")\n    text: str = Field(description=\"input a string\")\n```\nThen pass the pydantic class to your tool"}
{"instruction":"Where are the storage files of crewAI saved?", "input":"", "output":"The data storage files are saved into a platform-specific location found using the appdirs package, and the name of the project can be overridden using the CREWAI_STORAGE_DIR environment variable."}
{"instruction":"What database is used by `LongTermMemory`?", "input":"", "output":"The `LongTermMemory` uses SQLite3 to store task results."}
{"instruction":"How to add a knowledge source to my crew?", "input":"", "output":"Use the `knowledge_sources` attribute of the `Crew` class and pass a list of knowledge sources."}
{"instruction":"What are the types of knowledge sources that I can set?", "input":"", "output":"You can set multiple types of knowledge sources like:\n- CSV Files\n- PDF Files\n- TXT files\n- JSON files\n- XLSX files\n- MDX files\n- Websites"}
{"instruction":"How do I create a custom knowledge source?", "input":"", "output":"You can create a custom knowledge source by extending the `BaseKnowledgeSource` class from `crewai.knowledge.source.base_knowledge_source`\n```python\nfrom crewai.knowledge.source.base_knowledge_source import BaseKnowledgeSource\nclass SpaceNewsKnowledgeSource(BaseKnowledgeSource):\n    \"\"\"Knowledge source that fetches data from Space News API.\"\"\"\n```"}
{"instruction":"How can I chunk data for knowledge sources?", "input":"", "output":"You can use `chunk_size` and `chunk_overlap` to customize the chunking of content from the knowledge sources."}
{"instruction":"How can I set a custom embedder for my knowledge source?", "input":"", "output":"You can customize the embedding model by setting the `embedder` attribute. It supports various embedding models, for example you can use Google's model:\n```python\nembedder={\n\"provider\": \"google\",\n\"config\": {\n\"model\": \"models/text-embedding-004\",\n\"api_key\": GEMINI_API_KEY,\n}\n}\n```"}
{"instruction":"What does the `add()` method do in a custom knowledge source?", "input":"", "output": "It's used for processing and storing the content from your custom knowledge source."}
{"instruction":"What does the `_format_articles` method in the custom knowledge source example do?", "input": "", "output": "Formats the raw API response into a more readable text format for the agent to use."}
{"instruction":"How can I use `crewai-tools` inside my agent?", "input":"", "output":"Install them using `pip install \"crewai[tools]\"` or using the `crewai install` command, and then import the ones you want to use from `crewai_tools`. After you instantiate them, add them to the tools list."}
{"instruction":"Can the agent define tools?", "input":"", "output":"Yes, if `allow_code_execution=True`"}
{"instruction":"Can I use `crewai` offline without any internet connection?", "input":"", "output":"Yes, if you're using a local LLM model, you can use `crewai` without any internet connection."}
{"instruction":"What is gpt-4o?", "input":"", "output":"It's the default LLM used by `crewai` when no model is specified, provided by OpenAI."}
{"instruction":"Can I pass a crew to another crew as a tool", "input":"", "output":"Yes."}
{"instruction":"How can I use the `crewai` framework with a local model?", "input":"", "output":"Use Ollama + LiteLLM to serve a local model in an endpoint that mimics OpenAI"}
{"instruction":"How can I run a crew with a manager agent?", "input":"", "output":"Set `process=Process.hierarchical` when creating a crew, you also need to set either `manager_agent` or `manager_llm`."}
{"instruction":"How can I force the model to take its time?", "input":"", "output":"Set `max_iter` and `max_rpm` for both the task and the agent, and set `allow_delegation=False`."}
{"instruction":"What's the default value of `max_iter`?", "input":"", "output":"20"}
{"instruction":"I want to run a crew against multiple inputs and get all the results, how can I do it?", "input":"", "output":"Use `crew.kickoff_for_each()` and pass a list of inputs"}
{"instruction":"What is the difference between `crewai run` and `crewai crew run`?", "input":"", "output":"`crewai run` detects if your project is a crew or a flow, `crewai crew run` specifically runs crews."}
{"instruction":"What happens if an agent tries to use a tool that is not in its allowed tools list?", "input":"", "output":"It will receive an error and be prompted to use only the allowed tools."}
{"instruction":"What is the purpose of the `backstory` attribute in an `Agent`?", "input":"", "output":"The `backstory` provides context and personality to the agent, enriching interactions and guiding its behavior."}
{"instruction":"Can a `Task` have multiple agents assigned to it?", "input":"", "output":"No, a `Task` can only have one agent assigned to it directly, but the use of the Hierarchical Process, delegation, and CrewAI-Flow can give you the same outcome."}
{"instruction":"How can I control the level of detail in the output of an agent?", "input":"", "output": "The `verbose` parameter on an agent and crew allows you to control the output level."}
{"instruction":"What are the two ways to run a flow?", "input":"", "output":"You can either use the `crewai run` command or use the `kickoff()` method of the `Flow` class."}
{"instruction":"How can I define the starting point of my flow", "input":"", "output":"Use the `@start()` decorator to define the starting point of your flow."}
{"instruction":"I want a task to only run if another one is successful, how can I define that?", "input":"", "output":"Use the `or_()` and `and_()` methods to the `@listen` decorator"}
{"instruction":"How can I define a custom flow for my agent?", "input":"", "output":"You can use the new `crewai-flow` package to create a custom flow for your agent. It leverages a state machine to define the flow of execution of your agents."}
{"instruction":"How to define the type of a state in crewai-flow", "input":"", "output":"You can use the generic type `Flow[StateType]` to define the type of the state."}
{"instruction":"How to define the possible actions from a task in crewai-flow", "input":"", "output":"Use the `@listen` decorator to define the possible actions from a task.\n```python\n@listen(\"action_name\")\ndef next_task(self):\n ...\n```"}
{"instruction":"How to set the starting point of a flow in crewai-flow?", "input":"", "output":"Use the `@start` decorator to define the entrypoint to the flow.\n```python\n@start\ndef task_name(self):\n ...\n```"}
{"instruction":"How to define the end state of a flow?", "input":"", "output":"Use the `end` flow action to end the flow and return the output."}
{"instruction":"How to share context across a crewai-flow", "input":"", "output":"Use the `self.state` object to share the context across your flow. You can use either a generic python dictionary, or define a custom `pydantic` class for a more type-safe state."}
{"instruction":"How to conditionally run tasks inside a crewai-flow?", "input":"", "output":"You can use the `@router` decorator to define multiple exit points from a task, and chain tasks using the `@listen` decorator to decide which path to follow."}
{"instruction":"How can I make an agent ask for human input during a task execution?", "input": "", "output": "Set the `human_input` attribute to `True` on the `Task` object."}
{"instruction": "Where can I find an overview of all available commands in CrewAI?", "input": "", "output":"You can find an overview of all available commands in the CrewAI CLI documentation or by running `crewai --help`."}
{"instruction":"What are the different ways to pass input parameters to tasks in CrewAI?", "input": "", "output": "Input parameters can be passed to tasks through the `description` (using string formatting or f-strings), the `expected_output` (if it contains formatting placeholders), and through the `inputs` dictionary in the `crew.kickoff()` method (which allows variable substitution in YAML files)."}
{"instruction":"How do I handle sensitive information like API keys within CrewAI?", "input":"", "output":"Store sensitive information, such as API keys, in environment variables and access them using `os.environ`. Avoid hardcoding sensitive data directly in your code or YAML files. Using a `.env` file is a common and recommended approach."}
{"instruction": "I am getting a warning 'Input will be passed through to the crew and available in your YAML files as {input}'. What does this mean?", "input": "", "output": "This warning indicates that variables in your YAML files (like `{topic}` in the examples) will be replaced with values from your inputs when running the crew. It is letting you know about CrewAI's input variable substitution feature."}
{"instruction":"I'm getting an error related to tool usage. What could be the cause?", "input":"", "output": "Possible causes include:\n\n*   The tool is not installed or imported correctly.\n*   The agent is not authorized to use the tool (it's not in its `tools` list).\n*   The tool's input parameters are incorrect or missing.\n*  The tool is not a tool, check if the tool has been instantiated correctly.\n*   There is an error within the tool's `_run` method (for custom tools)."}
{"instruction":"How can I make my agents work in a more structured way?", "input": "", "output": "Use the hierarchical process (`Process.hierarchical`) and define a manager agent to coordinate tasks.  Also, consider using structured output formats (Pydantic models or JSON) and task guardrails to enforce data quality and consistency."}
{"instruction": "What should I check if my agent is not producing the expected output format?", "input":"", "output": "Verify that you have correctly set the `output_pydantic` or `output_json` attributes on the task. Also, check your agent's instructions and make sure they clearly specify the desired output format."}
{"instruction":"Can agents delegate tasks without the hierarchical process", "input": "", "output": "Yes, if `allow_delegation` is set."}
{"instruction":"How do I choose between `output_json` and `output_pydantic`?", "input": "", "output": "`output_json` provides basic structure using a JSON. `output_pydantic` allows defining custom classes and types for the output, giving more structure to it."}
{"instruction":"How can I ensure that the agent doesn't modify the output of a tool directly?", "input":"", "output": "Use `result_as_answer=True` when defining the tools for the agent."}
{"instruction":"How do I know if my agent can use the `code_execution`?", "input": "", "output":"Check if it's available and configured correctly, the agent should output a warning in the console if it isn't."}
{"instruction":"What should I do if my agent is stuck in an infinite loop?", "input":"", "output": "Check the `max_iter` attribute on the agent and the `max_retries` on the tasks. Lower these values if necessary. Review your task descriptions and agent instructions to ensure there are clear stopping conditions.  Use verbose logging to understand the agent's decision-making process."}
{"instruction":"How can I see the actual API calls made by a tool?", "input": "", "output": "Enable verbose logging (`verbose=True` on the agent or crew) to see the details of tool execution, including API calls if the tool is implemented to log them. You can use the AgentOps integration to get in depth monitoring."}
{"instruction":"What should I do if I get a `ValueError` related to task assignment?", "input": "", "output":"Make sure that *every* task in a sequential process has an `agent` assigned to it. In a hierarchical process, ensure that either `manager_agent` or `manager_llm` is set."}
{"instruction":"What is the difference between `crewai.tools` and `crewai_tools`?", "input": "", "output":"`crewai.tools` is the module inside the `crewai` package, where you define custom tools. `crewai_tools` is a separate package containing pre-built tools for common tasks."}
{"instruction":"What is the recommended way to structure a project with multiple crews?", "input":"", "output":"Use the project structure generated by `crewai create crew`. Create separate folders for each crew within the `crews` directory, and define each crew's agents, tasks, and configuration in separate files within its folder."}
{"instruction":"How do I provide a default value for an optional input parameter in a Pydantic model used for tool input?", "input": "", "output":"Use the `Field` function from Pydantic and set the `default` argument. For example: `my_optional_param: str = Field(default=\"default_value\", description=\"...\")`"}

{"instruction": "What's the best practice for naming my custom tools?", "input": "", "output": "The best practice is to give your custom tools descriptive names that clearly indicate their function.  Use a consistent naming convention (e.g., `VerbNounTool` like `SearchWikipediaTool`, `ReadFileTool`).  The `name` attribute of the tool should be a human-readable string, while the class name should follow Python's class naming conventions (PascalCase)."}
{"instruction": "How do I ensure my custom tool's description is used by the LLM?", "input": "", "output": "The `description` attribute of your `BaseTool` subclass (or the docstring of a function decorated with `@tool`) is *crucially* important.  This is what the LLM uses to understand the tool's purpose and when to use it.  Make it clear, concise, and specific, describing *what* the tool does, *what inputs* it takes, and *what output* it produces. Avoid being overly technical; describe it in plain language."}
{"instruction": "What happens if my custom tool's `_run` method doesn't return a string?", "input": "", "output": "The `_run` method of a `BaseTool` subclass *must* return a string.  If you need to return structured data, serialize it to a string format like JSON *within* the `_run` method before returning it. If you are using Pydantic models you can use the `response_format` parameter when instantiating your `LLM` class."}
{"instruction": "How can I make my custom tool asynchronous?", "input": "", "output": "To make a custom tool asynchronous, define the `_run` method as an `async def` function.  Make sure any I/O operations within `_run` use asynchronous libraries (e.g., `aiohttp` instead of `requests`)."}
{"instruction":"Can I define a custom prompt for an agent beyond just role, goal, and backstory?", "input":"", "output":"Yes, you can use `system_template` to define a custom prompt for your agent."}
{"instruction": "How can I use a custom embedding model with CrewAI's memory features?", "input": "", "output": "You can specify a custom embedding model using the `embedder` parameter when creating a `Crew` or an `Agent`. Provide a dictionary with `\"provider\"` and `\"config\"` keys.  The `config` will depend on the provider.  For example:\n\n```python\nembedder={\n    \"provider\": \"huggingface\",\n    \"config\": {\n        \"model\": \"sentence-transformers/all-mpnet-base-v2\"\n    }\n}\n```"}
{"instruction": "How can I load a custom LLM configuration from a file?", "input": "", "output": "CrewAI doesn't have a built-in mechanism for loading LLM configurations directly from files (unlike agent/task configurations).  You'll need to load the configuration file (e.g., using `json.load()` or `yaml.safe_load()`) and then use the loaded data to instantiate the `LLM` class."}
{"instruction": "What are some common mistakes to avoid when defining agents?", "input": "", "output": "Common mistakes include:\n\n*   **Unclear role/goal/backstory:** Make these as specific and descriptive as possible.\n*   **Overly broad tools:** Give agents only the tools they *need* for their tasks.\n*   **Missing or incorrect API keys:** Ensure environment variables are set correctly.\n*   **Ignoring context window limits:**  Be mindful of the LLM's context window and use summarization/memory features if needed.\n*   **Not handling errors:** Implement error handling in custom tools and consider task retries."}
{"instruction": "How can I test my custom tools independently of the full crew?", "input": "", "output": "You can instantiate your custom tool class directly and call its `_run` method with test inputs.  This allows you to isolate and debug the tool's logic before integrating it into a crew."}
{"instruction":"What is a good way to organize my CrewAI code if I have many custom tools?", "input":"", "output":"Create a separate `tools` directory (or package) within your project.  Within that directory, create separate Python files for each tool or group of related tools. This keeps your code modular and easier to maintain."}
{"instruction": "How does CrewAI handle concurrent requests to external APIs?", "input": "", "output": "CrewAI itself doesn't have built-in concurrency control for external API calls *within* a single crew execution (unless using `async_execution` or `kickoff_async`). If you're using a rate-limited API, you should use the `max_rpm` setting on the `Agent` or `Crew`.  If you're running *multiple* crews concurrently, you'll need to manage concurrency yourself (e.g., using `asyncio` and semaphores)."}
{"instruction": "How can I log the inputs and outputs of a specific tool?", "input": "", "output":"The easiest way is to add print statements within the `_run` method of your custom tool.  For more sophisticated logging, you could integrate a logging library (like Python's built-in `logging` module). You can use the agent `step_callback` to log the tool execution."}
{"instruction": "Can I dynamically change the tasks assigned to a crew after it has been created?", "input": "", "output": "No, the `tasks` list of a `Crew` object is fixed after creation.  If you need dynamic task assignment, consider using the hierarchical process with a manager agent that can create and delegate subtasks."}
{"instruction":"How can I access the results of all tasks executed by a crew?", "input":"", "output":"The `crew.kickoff()` method returns a `CrewOutput` object. This object has a `tasks_output` attribute, which is a *list* of `TaskOutput` objects, one for each task executed by the crew.  You can iterate through this list to access the results of each task."}
{"instruction": "What is the purpose of the `crewai.tools` module?", "input": "", "output": "The `crewai.tools` module (within the CrewAI library itself) is where you would define your *custom* tools. This is different from `crewai_tools`, which is a separate package for *pre-built* tools."}
{"instruction":"I'm getting a 'ModuleNotFoundError: No module named...' error. What should I check?", "input":"", "output":"Common causes for this error include:\n\n*   **Typos:** Double-check the spelling of the module name.\n*   **Installation:** Make sure the required package is installed (`pip install ...` or `uv add ...`).\n*   **Environment:** Ensure you're using the correct Python environment (virtual environment) where the package is installed.\n*   **PYTHONPATH:** In rare cases, your `PYTHONPATH` might not be configured correctly to find the module."}
{"instruction":"What's a good way to document my custom CrewAI tools?", "input":"", "output":"Use clear and descriptive `name` and `description` attributes in your `BaseTool` subclass. The `description` should explain *what* the tool does, *what inputs* it expects, and *what output* it produces, in language understandable by the LLM. Consider adding comments within the `_run` method to explain complex logic."}
{"instruction": "How can I use CrewAI to summarize a large amount of text?", "input": "", "output": "You could create a custom tool that uses a summarization library (like `transformers`).  You could also break down the summarization task into multiple subtasks: one to chunk the text, and another to summarize each chunk, and potentially a final task to combine the summaries. You can also use the `context` attribute on the task"}
{"instruction": "How can I handle situations where my LLM generates an output that's not in the expected format?", "input": "", "output": "Use task guardrails (`guardrail` attribute) to validate and, if necessary, reformat the output. You can also use the `output_pydantic` or `output_json` task attributes for more structured control over the output, providing a Pydantic model for output validation."}
{"instruction":"What are some strategies for improving the reliability of my CrewAI agents?", "input":"", "output":"Strategies for improving reliability include:\n\n*   **Clear Instructions:**  Provide very specific and unambiguous instructions in the agent's `role`, `goal`, and `backstory`, and in task descriptions.\n*   **Appropriate Tools:**  Give agents the right tools for the job, and make sure the tool descriptions are clear.\n*   **Guardrails:**  Use task guardrails to validate and correct outputs.\n*   **Error Handling:** Implement error handling within custom tools.\n*   **Retry Mechanisms:** Use `max_retries` on tasks to handle transient errors.\n*   **Testing:** Thoroughly test your agents and crews with a variety of inputs.\n* **Model Selection:** Choosing a model capable enough to handle your request."}
{"instruction": "What are some strategies to reduce prompt usage within CrewAI?", "input": "", "output": "Strategies to reduce prompt usage include:\n\n- **Caching:** Enabling caching (`cache=True`) on tools and agents to reuse results for identical inputs.\n- **Custom Embedder:** Define a custom embedder to reduce prompt usage\n- **Context:** Leveraging the context from previous tasks to inform subsequent ones.\n- **Manager LLM:** Specify a custom manager LLM or agent that is cheaper to run, for hierarchical processes."}
{"instruction": "Can I combine CrewAI with other AI frameworks or libraries?", "input": "", "output": "Yes, CrewAI is designed to be flexible and can be integrated with other libraries. You can use other AI frameworks within custom tools, or use CrewAI agents as part of larger workflows managed by other frameworks. It is also compatible with LangChain tools."}
{"instruction": "Where can I find more examples and use cases for CrewAI?", "input": "", "output": "Check the official CrewAI documentation, the GitHub repository (for examples and issues), and community forums or discussions. Also, blog posts and tutorials from other users can be valuable resources."}
{"instruction": "What kind of tasks are well-suited for the hierarchical process in CrewAI?", "input": "", "output": "The hierarchical process is well-suited for complex tasks that can be broken down into subtasks, and where coordination and oversight are beneficial.  Examples include: writing a long report with multiple sections, conducting in-depth research on a topic, planning a complex event, or developing a software application."}
{"instruction": "How can I monitor the performance of my CrewAI agents?", "input": "", "output":"You can use verbose mode (`verbose=True`) for basic logging, custom callbacks (`step_callback`, `task_callback`), and/or integrate with external monitoring tools like AgentOps."}
{"instruction":"How can I force my agent to use a specific tool?", "input":"", "output":"You can force your agent to use a specific tool by only giving them that tool, and defining the agent role, goal and backstory to promote the use of that tool. You can also use `result_as_answer=True`."}
{"instruction":"How can I use the `crewai-tools` package with my crew?", "input":"", "output":"To use `crewai-tools` you can install it through `pip install crewai-tools` or `crewai install`"}
{"instruction":"How can I make use of the `crewai-utilities` package in my projects?", "input":"", "output":"The `crewai-utilities` package can be installed using `pip install crewai-utilities`. It contains useful utilities to be used alongside `crewai`"}
{"instruction":"How can I run my crew with a local model?", "input":"", "output":"First, you need to download and install Ollama. Then, download the model you want, like `ollama pull llama3`. Then set up your agent to interact with the local model, by setting the `llm` attribute."}
{"instruction":"How can I make my agent interact with the real world?", "input":"", "output":"You can make your agent interact with the real world by using tools, like `crewai-tools` package and the `langchain-tools`"}
{"instruction":"Can a task know how long it took to execute?", "input":"", "output":"Not directly, but it will get logged if you set `verbose=True` on the task, agent or crew. You can also add a custom callback function to a task."}
{"instruction":"How do I make my agent use a tool that interacts with a specific API?", "input": "", "output": "You'll likely need to create a custom tool. Subclass `BaseTool` (or use the `@tool` decorator), and within the `_run` method, use a library like `requests` (or `aiohttp` for asynchronous requests) to interact with the API.  Make sure to handle API keys and authentication appropriately."}
{"instruction": "Can I use CrewAI to build a system that responds to real-time events?", "input": "", "output": "Yes, but you'll need to integrate CrewAI with an external system that handles the real-time event triggering. CrewAI itself doesn't have built-in mechanisms for listening to real-time events. You could use a message queue (like RabbitMQ or Kafka) or a webhook-based system to trigger CrewAI tasks in response to events."}
{"instruction":"How do I ensure that my agents are using the most up-to-date information?", "input":"", "output":"If the information is available through an API or a website, use tools that fetch data dynamically. If the information is in files, ensure those files are updated regularly.  Consider using a custom knowledge base with a mechanism for updating its content. You can also use `crewai reset-memories --knowledge` to reset the knowledge memory."}
{"instruction": "What are some techniques for making my agents more creative?", "input": "", "output": "To encourage creativity, you can:\n\n*   Use a higher `temperature` setting for the LLM.\n*   Provide less restrictive instructions in the task description.\n*   Give the agent a role and backstory that encourages creative thinking.\n*   Use tools that provide diverse or unexpected information."}
{"instruction":"What is the role of the `crewai.project` module?", "input":"", "output":"The `crewai.project` module provides decorators and base classes to use when structuring you project using YAML files for agents and tasks, these include, `@CrewBase`, `@agent`, `@task`, `@crew`, `@before_kickoff` and `@after_kickoff`"}
{"instruction":"How do I make sure a specific step is completed before my crew starts?", "input":"", "output":"You can use the `@before_kickoff` decorator to define custom pre-processing steps that you want your crew to run."}
{"instruction":"How do I execute a piece of code after my crew is completed?", "input":"", "output":"You can use the `@after_kickoff` decorator to define custom post-processing steps that you want your crew to run."}
{"instruction":"I get an error saying that `crewai` isn't installed when I run `crewai run`. What might be the issue?", "input":"", "output":"Double-check that you've installed `crewai` correctly (`pip install crewai` or `uv install crewai`). If you're using a virtual environment, make sure it's activated.  If you've installed it globally, ensure that your `PATH` environment variable includes the directory where `crewai` is installed."}
{"instruction":"Can an agent give itself a task?", "input":"", "output":"This isn't directly supported in the core CrewAI framework. However, with careful design and potentially a custom manager agent in a hierarchical process, you could create a system where an agent suggests a follow-up task, which the manager then approves and assigns. Direct self-assignment isn't a built-in feature, though."}
{"instruction":"How to use `crewai` with Azure OpenAI embeddings?", "input":"", "output":"```python\nfrom crewai import Crew, Agent, Task, Process\nfrom chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n\ncrew = Crew(\n    agents=[...],\n    tasks=[...],\n    process=Process.sequential,\n    memory=True,\n    verbose=True,\n    embedder={\n        \"provider\": \"openai\",\n        \"config\": {\n            \"api_key\": \"YOUR_API_KEY\",\n            \"api_base\": \"YOUR_API_BASE_PATH\",\n            \"api_version\": \"YOUR_API_VERSION\",\n            \"model_name\": 'text-embedding-3-small'\n        }\n    }\n)\n```"}
{"instruction":"What are the different types of memories supported in CrewAI?", "input": "", "output": "CrewAI supports short-term, long-term, entity, contextual, and user-specific memories. Short-term memory uses RAG and is useful for in-context recall. Long-term memory stores data in a SQLite3 database. Entity memory is for recognizing and remembering key entities. Contextual memory combines the other types of memories and User memory stores user-specific information and preferences."}
{"instruction": "How can I specify which embedding model to use with CrewAI memory features?", "input":"", "output": "You can customize the embedding model by using the `embedder` key while initializing the `Crew` or `Agent` class. It accepts `provider` and `config` as keys. The values you pass to them vary depending on the provider you're using, check out the documentation for more details."}
{"instruction": "How can I use environment variables for configuration in a CrewAI project?", "input": "", "output": "You can store configuration values, such as API keys and model names, in environment variables and access them in your code using `os.environ`. It is recommended to store those variables in a `.env` file in the root of your project."}
{"instruction":"If my agent needs to interact with a database, how should I approach that?", "input":"", "output":"The recommended approach is to create a custom tool that encapsulates the database interaction logic.  This tool would handle connecting to the database, executing queries, and formatting the results for the agent."}
{"instruction":"How can I make my CrewAI agents use different languages other than English?", "input":"", "output":"You can specify the language you want your crew to use by setting the `language` parameter in the `Crew` class. You can also use the `language_file` to point to a custom language file."}
{"instruction":"What is the purpose of the `crewai-tools` package?", "input":"", "output":"The `crewai-tools` package provides a collection of pre-built tools that you can easily integrate into your CrewAI agents. These tools cover common tasks like web searching, file reading, and more."}
{"instruction": "How to use the `crewai-utilities` package?", "input": "", "output":"`crewai-utilities` provides useful utilities to be used alongside `crewai`"}
{"instruction": "How can I contribute to the CrewAI project?", "input": "", "output": "You can contribute to CrewAI by submitting bug reports, suggesting new features, contributing code (via pull requests on GitHub), improving documentation, or sharing your projects and experiences with the community."}
{"instruction":"What's the relationship between CrewAI and LangChain?", "input":"", "output":"CrewAI is designed to work well with LangChain. You can use LangChain tools within CrewAI agents, providing a bridge between the two frameworks. However, CrewAI is a separate framework with its own focus on multi-agent collaboration."}
{"instruction":"How does the `AddImageTool` work in CrewAI?", "input": "", "output":"When `multimodal=True` is set on an agent, the `AddImageTool` is automatically made available.  It allows the agent to process images. The tool takes an `image_url` (a URL or local file path) and an optional `action` (a string describing what to do with the image) as input."}
{"instruction": "How do I use a local LLM with CrewAI?", "input": "", "output": "You can use a local LLM by setting the `llm` attribute of an `Agent` to an instance of the `LLM` class, configured to point to your local model.  For example, with Ollama and LiteLLM:\n\n```python\nfrom crewai import Agent, LLM\n\nagent = Agent(\n    # ... other attributes ...\n    llm=LLM(model=\"ollama/llama3\", base_url=\"http://localhost:11434\")\n)\n```"}
{"instruction":"What should I do if my agent is generating nonsensical or irrelevant output?", "input":"", "output":"Several things can cause this:\n\n*   **Unclear Instructions:** Make sure your task descriptions, agent roles, and goals are extremely clear and specific.\n*   **Insufficient Context:** Provide enough context to the agent, either through the task description or by using the `context` attribute to link to previous tasks.\n*   **Inappropriate LLM:** Ensure the LLM you're using is capable of handling the task.  Try a more powerful model.\n*   **Incorrect Tool Usage:** If the agent is using tools, make sure the tool descriptions are accurate and that the agent is using them correctly.\n* **Temperature:** Consider changing the temperature and top_p parameters of the LLM.\n*   **Prompt Engineering:** Experiment with different prompt phrasings and structures."}
{"instruction":"How can I use the `SerperDevTool` with CrewAI?", "input":"", "output":"First, install `crewai-tools` (`pip install crewai-tools`). Then, import `SerperDevTool`, instantiate it, and add it to an agent's `tools` list. Make sure you have set the `SERPER_API_KEY` environment variable. Example:\n\n```python\nfrom crewai_tools import SerperDevTool\n\nsearch_tool = SerperDevTool()\nagent = Agent(..., tools=[search_tool])\n```"}
{"instruction":"How do I load a configuration for a crew from a YAML file?", "input":"", "output":"Use the `CrewBase` class and the `@crew`, `@agent`, and `@task` decorators to load configurations from YAML files (`agents.yaml` and `tasks.yaml`). Refer to the documentation for the specific structure and usage."}
{"instruction":"How can I define custom error messages for my task guardrails?", "input":"", "output":"When your guardrail function returns `False` (indicating failure), the second element of the returned tuple should be an error message or an object containing error details.  You can customize this message to be as specific as possible.\n\n```python\ndef validate_length(text):\n  if len(text) > 100:\n    return False, {\"error\": \"Text is too long\", \"max_length\": 100}\n  return True, text\n```"}
{"instruction": "What should I consider when choosing between sequential and hierarchical processes?", "input": "", "output": "Consider the nature of your tasks:\n\n*   **Sequential:** Best for tasks that have a clear, linear order of operations.\n*   **Hierarchical:** Best for complex tasks that can be broken down into subtasks, require coordination, and benefit from a manager agent's oversight."}
{"instruction": "What's the easiest way to get started with CrewAI if I'm new to the framework?", "input": "", "output": "The recommended way is to use the `crewai create crew` command to create a new project. This provides a working example that you can modify. Also, follow the quickstart guide in the official documentation."}
{"instruction":"How do I ensure data consistency when using asynchronous tasks?", "input":"", "output":"When using asynchronous tasks, be mindful of potential race conditions if multiple tasks might modify shared data.  Use appropriate synchronization mechanisms (like locks or queues) if necessary, or design your tasks to avoid shared mutable state."}
{"instruction": "Can I use CrewAI to build a system that interacts with users in real-time?", "input": "", "output": "CrewAI itself is primarily focused on agent orchestration. For real-time user interaction, you'd integrate CrewAI with a separate framework that handles user input and output (e.g., a web framework, a chatbot platform)."}
{"instruction": "Can I use CrewAI for tasks that require physical actions (e.g., controlling a robot)?", "input": "", "output": "CrewAI is primarily designed for information-processing tasks. While you *could* theoretically use it to control a robot (by creating custom tools that send commands to the robot), it's not the primary use case.  You'd likely need to integrate it with a robotics framework."}
{"instruction": "How can I visualize the execution flow of my CrewAI crew?", "input": "", "output": "You can use the crew.plot() method to visualize the execution flow of your CrewAI crew. This allows you to understand the flow and debug the agents behavior. If you're using `crewai-flow` you can run `crewai flow plot` in your CLI."}
{"instruction":"What's a good approach for handling very long documents or large datasets with CrewAI?", "input":"", "output":"Break down the task into smaller, manageable subtasks.  Use techniques like chunking (for text) or pagination (for APIs) to process the data in smaller units.  Consider using tools specifically designed for handling large files or datasets."}
{"instruction":"How can I get help if I'm stuck with a CrewAI problem?", "input":"", "output":"Consult the official documentation, check the GitHub repository for issues and discussions, and consider joining the CrewAI community (if one exists) to ask questions and share experiences."}
{"instruction": "What is the purpose of the `crewai.process.Process` class?", "input": "", "output": "The `crewai.process.Process` class is an `Enum` that defines the available process types for a `Crew`: `sequential` and `hierarchical`."}
{"instruction": "How can I customize the behavior of the manager agent in a hierarchical process?", "input": "", "output": "You can either define a custom `Agent` instance and pass it as the `manager_agent` when creating the `Crew`, or you can specify a custom language model using the `manager_llm` parameter."}
{"instruction": "What is the advantage of using Pydantic models for task output (`output_pydantic`)?", "input": "", "output": "Using `output_pydantic` provides several advantages:\n\n*   **Structured Output:**  Ensures the output is in a specific, predictable format.\n*   **Validation:**  Pydantic models automatically validate the output, raising errors if it doesn't conform to the schema.\n*   **Type Safety:**  Provides type hints and helps catch errors during development.\n*   **Easy Access:**  You can access output fields as attributes of the Pydantic model (e.g., `result.title`)."}
{"instruction": "What's the relationship between CrewAI tasks and tools?", "input": "", "output": "Tasks define *what* needs to be done, while tools provide the *how*.  A task might specify that information needs to be gathered, and the agent assigned to that task would use an appropriate tool (e.g., a web search tool) to accomplish it."}
{"instruction":"What happens if an agent tries to use a tool that's not in its `tools` list?", "input": "", "output":"If an agent attempts to use a tool that is not included in its allowed `tools` list, it will result in an error. The agent will receive feedback indicating that it does not have access to the requested tool."}
{"instruction":"Can a task be assigned to multiple agents?", "input": "", "output":"No. At the `Task` level you can only assign one agent, but you can use delegation to achieve the same result."}
{"instruction": "How do I use a custom embedding model with CrewAI?", "input": "", "output":"You can specify a custom embedding model using the embedder parameter when creating a Crew or an Agent. This parameter accepts a dictionary with provider and config keys. The configuration details depend on the chosen provider."}
{"instruction": "Where should I put my custom tool definitions in a CrewAI project?", "input": "", "output":"It's recommended to place custom tool definitions in a `tools` directory (or package) within your project.  This keeps your code organized and modular."}
{"instruction": "How can I debug a situation where my agent is not using the tools I expect it to use?", "input": "", "output": "Enable verbose logging (`verbose=True`). Carefully review the agent's `role`, `goal`, `backstory`, and the `description` of the tools. Ensure that the tool descriptions are clear and unambiguous, and that they accurately reflect the tool's capabilities. Consider using a more powerful LLM."}
{"instruction": "Can I use CrewAI to orchestrate tasks that involve human interaction?", "input": "", "output": "Yes, you can use the `human_input` attribute on a `Task` to request human input. You'd need to integrate CrewAI with a mechanism for collecting that input (e.g., a web form, a command-line prompt)."}
{"instruction":"How does the `allow_delegation` attribute work?", "input": "", "output":"The `allow_delegation` attribute on an `Agent` determines whether that agent is allowed to delegate tasks to other agents.  It's `False` by default."}
{"instruction":"How do I use the `crewai` CLI to create a new project?", "input":"", "output":"Use the command `crewai create crew <project_name>` to create a new project with the basic directory structure and example files."}
{"instruction":"How do I set API keys and other sensitive information for my CrewAI project?", "input":"", "output":"Use environment variables. It is best practice to use a `.env` file in the root of the project."}
{"instruction":"How can I check which version of CrewAI I have installed?", "input":"", "output":"Run `crewai version` in your terminal."}
{"instruction":"How do I specify which LLM a CrewAI agent should use?", "input":"", "output":"You can specify the LLM using the `llm` parameter when creating an `Agent`. You can pass either a string identifier (like 'gpt-4') or an instance of the `LLM` class."}
{"instruction":"How can I make a task wait for the completion of multiple other tasks before it starts?", "input":"", "output":"Use the `context` attribute of the `Task` and provide a list of the tasks it depends on. For example: `context=[task1, task2]`"}
{"instruction":"What's the difference between setting `verbose=True` on an `Agent` versus on a `Crew`?", "input":"", "output":"Setting `verbose=True` on an `Agent` will only show verbose output for *that specific agent*. Setting it on the `Crew` will show verbose output for *all* agents within that crew."}
{"instruction":"How can I contribute to the development of CrewAI?", "input":"", "output":"You can contribute by reporting bugs, suggesting features, contributing code (via pull requests on GitHub), improving documentation, or sharing your projects and experiences with the community."}
{"instruction": "Can I use CrewAI to build a system that processes data in real-time?", "input": "", "output": "CrewAI can be part of a real-time system, but it doesn't directly handle real-time data streams.  You'd need to integrate it with a system that provides the real-time data (e.g., a message queue, a streaming data platform)."}
{"instruction": "How can I prevent my agents from hallucinating or making up information?", "input": "", "output": "While you can't completely eliminate hallucination, you can mitigate it by:\n\n*   Using more powerful and reliable LLMs.\n*   Providing clear and specific instructions.\n*   Giving agents access to reliable tools and knowledge sources.\n*   Using task guardrails to validate outputs.\n*   Adding specific instructions in the agent's `backstory`."}
{"instruction":"How can I create a custom prompt template for an agent in CrewAI?", "input": "", "output":"You can create a custom prompt template using the `system_template` attribute. This attribute accepts a string that defines the structure and content of the system prompt sent to the agent. You can use placeholders within the template string to insert dynamic values, such as the agent's role, goal, or context from previous tasks."}
{"instruction":"How to create custom prompts?", "input":"", "output":"You can create custom prompts using:\n- `system_template` which defines the system format for the agent.\n- `prompt_template` which defines the prompt format for the agent.\n- `response_template` which defines the response format for the agent.\n\nThese attributes can include placeholders (e.g., `{role}`, `{goal}`, `{input}`), and allow you to have dynamic conversations with the model."}

{"instruction": "How can I use Ollama with CrewAI?", "input": "", "output": "First, install and run Ollama. Pull a model using `ollama pull <model_name>`. Then, configure your agent's `llm` attribute to point to the Ollama server:\n\n```python\nfrom crewai import Agent, LLM\n\nagent = Agent(\n    # ... other attributes ...\n    llm=LLM(model=\"ollama/<model_name>\", base_url=\"http://localhost:11434\")\n)\n```\nReplace `<model_name>` with the actual model name (e.g., `llama3`)."}
{"instruction": "How to install crewai with all the tools?", "input": "", "output": "Use the command `pip install 'crewai[tools]'` to install with all available tools."}
{"instruction":"What happens if my crew has cyclic task dependencies (Task A depends on Task B, which depends on Task A)?", "input":"", "output":"CrewAI will detect cyclic dependencies and raise an error. You need to design your tasks and their `context` attributes to avoid creating cycles."}
{"instruction": "How can I use a custom knowledge source to inform my CrewAI agents?", "input": "", "output": "You can create custom knowledge sources by extending the `BaseKnowledgeSource` class. You'd implement methods to load, process, and chunk your data. Then, you can add instances of your custom knowledge source to the `knowledge_sources` list when creating an `Agent` or `Crew`."}
{"instruction":"How can I use the `crewai-tools` package?", "input":"", "output":"Install the package using `pip install crewai-tools` or `crewai install`. Then, import the desired tools from the `crewai_tools` module and add them to your agent's `tools` list."}
{"instruction":"What is the purpose of the `crew.plot()` method", "input":"", "output":"The plot method allows you to generate an HTML file with a visual representation of your flow, making it easier to understand the sequence and connection"}
{"instruction":"How can I define a task to be executed only if a condition is met?", "input": "", "output": "Use the new `crewai.tasks.ConditionalTask` class. This allows defining a task to be executed only if a condition is met, using the output of the previous tasks as input for the condition."}
{"instruction":"How can I run a task multiple times?", "input": "", "output":"Use the `crew.kickoff_for_each()` providing a list of inputs."}

